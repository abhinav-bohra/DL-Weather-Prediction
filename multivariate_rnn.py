# -*- coding: utf-8 -*-
"""Multivariate_RNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pDem4ssm-LjIt8lARcguedx286pcwocc

# Weather Prediction using RNNs 

## By Rahul Mondal, 18MF3IM31
---

In this Notebook, we show how the long-term trend of rainfall can be predicted with decent accuracy using key weather parameters (humidity, temperature, atmospheric pressure, etc.) with a simple recurrent neural network (RNN). A simple one-layer RNN based model seems sufficient to be able to predict long-term trends from limited training data surprisingly well.
"""

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/
!git clone https://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@github.com/abhinav-bohra/RNN-Weather-Prediction.git
# %cd /content/RNN-Weather-Prediction

!git pull

"""# **Multivariate Time Series Model**
---
"""

#--------------------------------------------------
# Importing Libraries
#--------------------------------------------------
import time
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from keras.models import Sequential
from keras.callbacks import Callback
from datetime import datetime, timedelta
from keras.layers import Dense, SimpleRNN
from tensorflow.keras.optimizers import RMSprop

pd.set_option('mode.chained_assignment', None)
pd.options.display.max_columns = None

"""## **1. Data loading and pre-processing**

### 1.1 Loading the dataset
"""

#--------------------------------------------------
# Loading the dataset
#--------------------------------------------------
raw_df = pd.read_csv( "weather_data.csv", sep = ',', na_values = ['', ' '])
raw_df.columns = raw_df.columns.str.lower().str.replace(' ', '_')

#--------------------------------------------------
# Pre-processing the dataset
#--------------------------------------------------
full_df = raw_df.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)

print(full_df.head())

df = full_df[['hum9', 'pres9', 'temp9', 'winds9']]

#Normalization
df['hum9']=(df['hum9']-df['hum9'].mean())/df['hum9'].std()
df['pres9']=(df['pres9']-df['pres9'].mean())/df['pres9'].std()
df['temp9']=(df['temp9']-df['temp9'].mean())/df['temp9'].std()
df['winds9']=(df['winds9']-df['winds9'].mean())/df['winds9'].std()

df['raint'] = pd.get_dummies( full_df['raint'], drop_first=True).rename(columns = {'Yes':'raint'})

print(df.head())

"""### 1.2 Data Visualization"""

def plot_train_points(df,Tp=7000):
    plt.figure(figsize=(7,2))
    plt.title("Rainfall of first {} data points".format(Tp),fontsize=11)
    plt.plot(df['raint'][:Tp],c='k',lw=1)
    plt.grid(True)
    plt.xticks(fontsize=10)
    plt.yticks(fontsize=10)
    plt.show()

plot_train_points(df)

"""### 1.4 Train-Test Split"""

#Train: 80% Test: 20%
Tp = int(len(df)*0.8)
train = np.array(df[:][:Tp])
test = np.array(df[:][Tp:])

"""### 1.5 Choose the embedding or step size
RNN model requires a step value that contains n number of elements as an input sequence. Here, we choose `step=8`. In more complex RNN and in particular for text processing, this is also called _embedding size_. The idea here is that **we are assuming that 8 hours of weather data can effectively predict the 9th hour data, and so on.**
"""

step = 90

# add step elements into train and test
test_last = np.repeat(test[-1,:].reshape(-1,1),step, axis=1).swapaxes(0,1)
test = np.concatenate((test, test_last), axis=0)

train_last = np.repeat(train[-1,:].reshape(-1,1),step, axis=1).swapaxes(0,1)
train = np.concatenate((train, train_last), axis=0)

print("Train data length:", train.shape)
print("Test data length:", test.shape)

"""### 1.6 Converting to a multi-dimensional array
Next, we'll convert test and train data into the matrix with step value as it has shown above example.
"""

def convertToMatrix(data, step):
    X, Y =[], []
    for i in range(len(data)-step):
        d=i+step  
        X.append(data[i:d,:,])
        Y.append(data[d,-1])
    return np.array(X), np.array(Y)

trainX,trainY = convertToMatrix(train,step)
testX,testY = convertToMatrix(test,step)

print("Training data shape:", trainX.shape,', ',trainY.shape)
print("Test data shape:", testX.shape,', ',testY.shape)

"""## **2. Modeling**

### Keras model with `SimpleRNN` layer

A simple function to define the RNN model. It uses a single neuron for the output layer because we are predicting a real-valued number here. As activation, it uses the ReLU function. Following arguments are supported.

- neurons in the RNN layer
- embedding length (i.e. the step length we chose)
- nenurons in the densely connected layer
- learning rate
"""

import tensorflow as tf

def build_rnn(num_units=128, embedding=14, num_dense=32, lr=0.001, num_features=4):
    """
    Builds and compiles a simple RNN model
    Arguments:
              num_units: Number of units of a the simple RNN layer
              embedding: Embedding length
              num_dense: Number of neurons in the dense layer followed by the RNN layer
              learning_rate: Learning rate (uses RMSprop optimizer)
    Returns:
              A compiled Keras model.
    """
    model = Sequential()
    model.add(SimpleRNN(units=num_units, input_shape=(embedding, num_features), activation="relu"))
    model.add(Dense(num_dense, activation="relu"))
    model.add(Dense(1, activation="sigmoid"))
    # model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['mse'])
    model.compile(optimizer=RMSprop(learning_rate=lr), loss='binary_crossentropy', metrics=['mse'])

    return model

model_rainfall = build_rnn(embedding=step, num_features=len(df.columns), lr=0.001)

model_rainfall.summary()

# Keras `Callback` class to print progress of the training at regular epoch interval
class MyCallback(Callback):
    def on_epoch_end(self, epoch, logs=None):
        if (epoch+1) % 50 == 0 and epoch>0:
            print("\n\nEpoch number {} done".format(epoch+1))

# Batch size and number of epochs
batch_size = 128
num_epochs = 512

"""### Training the model"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# model_rainfall.fit( trainX, trainY, 
#                     epochs=num_epochs, 
#                     batch_size=batch_size, 
#                     callbacks=[MyCallback(), tf.keras.callbacks.EarlyStopping(monitor='mse', patience=5)],verbose=1)

"""### Plot RMSE loss over epochs"""

plt.figure(figsize=(7,5))
plt.title("RMSE loss over epochs",fontsize=16)
plt.plot(np.sqrt(model_rainfall.history.history['mse']),c='k',lw=2)
plt.grid(True)
plt.xlabel("Epochs",fontsize=14)
plt.ylabel("Root-mean-squared Error",fontsize=14)
plt.xticks(fontsize=14)
plt.yticks(fontsize=14)
plt.show()

"""## Result and analysis

### Predict the future points
Now, we can generate predictions for the future by passing `testX` to the trained model.
"""

threshold = 0.95

#Predictions on Train Set
trainPredict = model_rainfall.predict(trainX)
trainPredict = [1 if p>=threshold else 0 for p in trainPredict]

#Predictions on Test Set
testPredict= model_rainfall.predict(testX)
testPredict = [1 if p>=threshold else 0 for p in testPredict]

#Predictions on Train + Test Set
predicted=np.concatenate((trainPredict,testPredict),axis=0)

plt.figure(figsize=(10,2))
plt.title("This is what the model predicted")
x_axis = np.arange(1, 1+len(testPredict), 1, dtype=int)
plt.scatter(x_axis, testPredict, c='orange')
plt.show()

"""### Plotting the ground truth and model predictions together
Plotting the ground truth and the model predictions together to see if it follows the general trends in the ground truth data
"""

index = df.index.values

plt.figure(figsize=(10,3))
plt.title("Rainfall: Ground truth and prediction together")
plt.plot(index,df['raint'],c='blue')
plt.plot(index,predicted,c='orange',alpha=0.75)
plt.legend(['True data','Predicted'])
plt.axvline(x=Tp, c="r")
plt.grid(True)
plt.ylim(0,1)
plt.show()

"""## **Perfromance Evaluation**"""

from sklearn.metrics import classification_report
trainTruth = df['raint'][:Tp]
testTruth = df['raint'][Tp:]
cm_train = classification_report(trainTruth, trainPredict)
cm_test = classification_report(testTruth, testPredict)
cm_full = classification_report(df['raint'], predicted)

print(cm_train)

print(cm_test)

print(cm_full)

"""## Performance on test set"""

def measure_performance (clasf_matrix):
    measure = pd.DataFrame({
                            'sensitivity': [round(clasf_matrix[0,0]/(clasf_matrix[0,0]+clasf_matrix[0,1]),2)], 
                            'specificity': [round(clasf_matrix[1,1]/(clasf_matrix[1,0]+clasf_matrix[1,1]),2)],
                            'precision': [round(clasf_matrix[0,0]/(clasf_matrix[0,0]+clasf_matrix[1,0]),2)],
                            'recall': [round(clasf_matrix[0,0]/(clasf_matrix[0,0]+clasf_matrix[0,1]),2)],
                            'overall_acc': [round((clasf_matrix[0,0]+clasf_matrix[1,1])/(clasf_matrix[0,0]+clasf_matrix[0,1]+clasf_matrix[1,0]+clasf_matrix[1,1]),2)]
                          })
    return measure

def my_acc(testTruth, testPredict):
  cnt=0
  for g,p in zip(testTruth, testPredict):
    if g==p:
      cnt=cnt+1
  return cnt/len(testTruth)

from sklearn import metrics
from sklearn.metrics import confusion_matrix
cm = metrics.confusion_matrix(testTruth, testPredict)
rnn_metrics_df = pd.DataFrame(measure_performance(cm))

print("-"*100)
print(rnn_metrics_df)
print("-"*100)
print( f'Total Accuracy sklearn: {np.round( 100*metrics.accuracy_score( testTruth, testPredict ), 2 )}%')
print( f'Total Accuracy me     : {np.round( 100*my_acc( testTruth, testPredict ), 2 )}%')

multivar step 14 79.26
multivar step 30 79.45
multivar step 90 79.51

